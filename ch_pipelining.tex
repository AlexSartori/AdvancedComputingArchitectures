\chapter{Pipelining}

The basic idea of Pipelining is to divide the elementary operations related to a single instruction into a sequence of smaller task that can be performed in parallel.

The goal is to balance the length of each pipeline stage. In this way the time taken per instruction (pipelined) when the pipeline is full is:

\textit{Time per instruction (unpipelined)} / \textit{Number of stages}

\textbf{Pipelining reduces the average CPI.}

\section{Ideal pipelining}

\[ t_s = t_o + T_i/ p \]

where \\
$t_o$ is the overhead latency of each stage;\\
p is the number of stages; \\
$T_i$ is the total latency of a single instruction;

The \textbf{CPI} is the number of clocks required (on average) to complete one instruction after the previous one has completed.

In a pipeline, the throughput of any instruction sequence (i.e., the number of completed instruction per unit of time) is \textbf{about p times larger} than in the unpipelined solution.
CPI is asymptotically equal to 1.
Average Instruction Execution Time $T_e = T_{CLK} * CPI$

\section{Pipeline in a RISC CPU (MIPS)}
\paragraph{MIPS features}
\begin{itemize}
    \item 32 64-bit general purpose register (GPR), named R0, R1, ..., R31. (R0 = 0)
    \item 32 floating-point registers (FPR), named F0, F1, ..., F31.
    \item Data types: 8-bit bytes, 16-bit half words, 32-bit words, 64-bit double words.
    \item Addressing modes:
    \begin{itemize}
        \item Immediate: ADD R4, \#3
        \item Displacement: LD R4, 100(R1)
        \item Register indirect: LD R4, 0(R1)
        \item Absolute addressing: LD R4, 2536(R0)
    \end{itemize}
    \item Load/store architecture
\end{itemize}

\subsection{Instruction Execution stages}
\includegraphics[width=\textwidth]{images/mips_scheme.png}

Stages:
 \begin{itemize}
    \item \textit{Instruction fetch stage (IF)}:\\ Send the program counter (PC) to memory and fetch the current instruction from memory or I-cache. Update the PC to next sequential value (e.g. by adding 4 if an instruction is 4 byte long)
    \item \textit{Instruction Decode/ register fetch stage (ID)}:\\decode the instruction and perform simultaneous operand reading. Instruction decode and operand reading can be done in parallel because RISC instructions are fixed-field encoded. \\
    • In case of register operands read the source registers values from the register file\\
    • In case of immediate operands, sign-extend the offset field of the instruction
    \item \textit{Execution/effective address stage (EX)}:\\
    The ALU operates on the operands prepared in the previous cycle, performing different operations depending on the instruction type.\\
    • Load/store instructions: The ALU adds the base register and the offset to form the effective address. \\
    • Register-Register ALU instructions: The ALU performs the operation specified in the ALU opcode on the values read from the register file \\
    • Register-Immediate ALU instructions:The ALU performs the operation specified by the ALU opcode on the value read from the specified register and the sign-extended immediate \\
    • Branch instructions: The ALU adds the next instruction value to the extended value of the address (multiplied by 4) to calculate the branch target address (BTA).
    In conditional branches the value of the condition register is compared with the reference value (i.e., 0) and stored into a special register.
    \item \textit{Memory access stage(MEM)}:\\
    – Load instructions: The memory performs a read using the effective address computed in the previous cycle using A and Imm and saved in ALU output\\
    – Store instructions: The memory performs a write using the effective address computed in the previous cycle using A and Imm and saved in ALU output, while the value comes from the other register, saved in B\\
    – Branch instructions: in branches, the PC is replaced with the BTA (saved in ALU output) according to the outcome of the comparison with zero, saved in Cond
    \item \textit{Write-back stage(WB)}:\\
    –Loads and ALU instructions: Write the result into the register file, whether it comes from the memory system (for a load) or from the ALU (for an ALU instruction)
\end{itemize}

It is important to \textbf{perform approximately the same amount of work in each stage}. In fact, the clock cycle of the processor depends on latency of the stage with the worst-case delay.

\includegraphics[width=\textwidth]{images/mips_pipeline.png}

Instructions are fetched and initiated at every clock cycle filling all the stages. In this way the CPU will be perfectly busy. For this, the following basic modifications have to be applied:
\begin{itemize}
\item Insert homogeneous registers or latches between stages (IF/ID, ID/EX, EX/MEM, MEM/WB) thus replacing (i.e. including) temporary registers
\item Propagate the control signals generated by the CU as well as the status bits of each instruction within the same pipeline registers
\item Anticipate the PC contents update operation to the IF stage (instead of running it in the MEM stage) to avoid fetch latencies
\end{itemize}

\includegraphics[width=\textwidth]{images/mips_pipeline_stages.png}

Why isn't the speed-up = 5?
The unpipelined version skips certain stages when not needed and the pipelined version has a 20\% clock overhead.

\section{Hazards}
The presence of several instructions simultaneously active into the pipeline may lead to various type of dependencies which turn into hazards. Hazards reduce the performance from the ideal speedup by forcing the pipeline to \textbf{stall}, i.e., to delay subsequent instructions until the source of the hazard is solved. Hazards can be solved using \textit{hardware techniques}, \textit{software techniques} or a combination of both.

\subsection{Structural hazard}
Arise from resource conflicts when the hardware can not support all possible combinations of instructions at the same time.

In a pipelined processor, the overlapped execution of instructions requires pipelining of functional units and duplication of resources. If some combination of instruction requires to use the same resource a structural hazard arise.

To avoid structural hazards (which would lead to incorrect results), the pipeline is stalled -> 1  or more “empty”cycles or bubbles are inserted in the pipeline.

\textbf{Stalls result in a reduction of instruction throughput.}

Other solutions:
\begin{itemize}
    \item Hardware:\\
    Resource splitting/replication but it's expensive!
    \item Software:\\
    Instructions requesting the same resource are located at proper distance from each other. For instance, two conflicting instructions could be delayed by the compiler. It's effective but compiler design could be cumbersome!
\end{itemize}

\paragraph{Impact of hazards on CPI}
Say the probability of a stall is 20\%: 1 stall every 5 instructions

$CPI = \frac{\#clocks}{\#instr} = \frac{IC + (\frac{IC}{5} - 1)}{IC} = 1 + \frac{1}{5} - \frac{1}{IC}$

\subsection{Data hazard}
Data hazards are related to \textbf{data dependencies}, i.e., sequential constraints imposed by the data flow of the program.
Two different instructions are data dependent if they have a common register or memory location; unless the operand is for both a \textit{source operand}.

Data dependencies can occur in:
\begin{itemize}
    \item \textbf{Straight-line code}: between subsequent instructions during the execution of a program segment
    \item \textbf{Loops}: between instructions belonging to different iterations of the loop (also called \textit{recurrences} or \textit{inter-iteration dependences})\\
Example: first-order linear recurrences: e.g.: X(i) = A(i) * X(i-1) + B(i)
\end{itemize}

Three kinds of data dependences:
\begin{itemize}
    \item \textbf{Read after Write (RAW)} also called flow or true dependence\\
    A read uses the value written by a write instruction.\\
    \includegraphics[width=\textwidth]{images/RAW_scheme.png}
    
    \item \textbf{Write after Read (WAR)} also called anti dependence\\
    The destination of an instruction is a source operand of a previous instruction.\\
    \includegraphics[width=\textwidth]{images/WAR_scheme.png}
    
    \item \textbf{Write after Write (WAW)} also called output dependence\\
    Two instructions have the same destination operand.\\
    \includegraphics[width=\textwidth]{images/WAW_scheme.png}
\end{itemize}

\paragraph{Solutions to data hazards}
\begin{itemize}
    \item WAR, WAW are \textbf{false dependences}: 
    they can be solved through renaming (during compilation or by means of specialized hardware)\\
    \includegraphics[width=\textwidth]{images/renaming_solution_data_hazard.png}
    
    \item RAWs are \textbf{true dependences}
\end{itemize}

One RAW hazard example on a 5-stage pipeline:\\
\includegraphics[width=\textwidth]{images/RAW_hazard_example.png}

\paragraph{Software solutions}
\begin{itemize}
    \item \textit{Code moving}:\\
    If possible, the compiler inserts as many non-dependent instructions as necessary (3 instructions in the case considered) between define and first use of a variable.\\
    \includegraphics[width=\textwidth]{images/data_hazard_sol1.png}
    
    \item \textit{Nop stuffing}:\\
    The compiler inserts as many nop as are the required cycles between define and first use; So do not perform any active computation.\\
    \includegraphics[width=\textwidth]{images/data_hazard_sol2.png}
\end{itemize}

\paragraph{Hardware solutions}
The CU of the pipeline:
\begin{enumerate}
    \item Check (in the ID stage) whether one of the source register $r_{s1}$ and $r_{s2}$ of the considered instruction $I_{k+1}$ coincides with the destination register $r_d$ of some previous incomplete instruction. 6 comparisons are required:\\
    IF/ID.IR($r_{s1}$) == ID/EX.IR($r_d$) \|  IF/ID.IR($r_{s2}$) == ID/EX.IR($r_d$)\\
    IF/ID.IR($r_{s1}$) == EX/MEM.IR($r_d$) \|  IF/ID.IR($r_{s2}$) == EX/MEM.IR($r_d$)\\
    IF/ID.IR($r_{s1}$) == MEM/WB.IR($r_d$) \|  IF/ID.IR($r_{s2}$) == MEM/WB.IR($r_d$)
    
    \item If a hazard is detected, the CU stalls the conflicting instruction $I_{k+1}$ in the ID stage until the instruction $I_k$ has completed its flow (pipeline interlock). Same as a nop but with less instruction memory space.
\end{enumerate}
\includegraphics[width=\textwidth]{images/pipeline_CU_scheme.png}

\paragraph{Forwarding}
We can use forwarding to reduce the stall penalty. Briefly in some cases instead of waiting that the information will be written in the registers we can simply forward them from a inter-stage pipeline register to another one.

Thus we can implement forwarding control by multiple comparisons between EX/MEM.IR(rd) and MEM/WB.IR(rd) with ID/EX.IR(rs) and EX/MEM.IR(rs). Increasing HW complexity due to comparators and MUX enlargement.

Not all RAW hazard can be handled by forwarding. This happens when certain data is required at ALU inputs before it is ready. In this case forwarding reduces stall penalty, but it can not prevent some “bubbles”.

\includegraphics[width=\textwidth]{images/pipeline_scheme_forwarding.png}

\subsection{Control hazard}
Control dependences are sequential constraints due to the control flow of the program.
All branch instructions (e.g. jumps, procedure calls and returns, traps, interrupt) create control dependences.

If a branch changes the PC, it is referred to as a \textbf{taken branch}; if it falls through, it is not taken, or \textbf{untaken}.

\textit{Control hazards} are related to the risk of fetching into the pipeline the wrong instructions following a conditional branch before knowing if the branch has to be taken or not.
For example when we have a beq followed by some other instructions, without any control the following instructions will be fetched before the beq instruction enters in the MEM stage. There is a control hazard.

\paragraph{Solutions}
\begin{enumerate}
    \item \textit{Freezeor flush the pipeline}:\\
    Hold or delete any instruction after the branch until the BTA is known
    \item \textit{Predict branch as not taken}:\\
    As PC+4 is already calculated, the hardware continues to fetch instructions in sequence as if the branch were not executed. If the branch is actually taken, wrongly fetched instructions have to be “flushed” (i.e., turned into nops)
    \item \textit{Predict Branch as Taken}:\\
    As soon as the branch is decoded and the BTA is calculated, we begin fetching instructions from BTA. If the branch was not to be taken, wrongly fetched instructions are “flushed” (like in solution 2).This solution is meaningful only if the BTA is known before branch outcome.
    \item \textit{Branch hoisting (delay slots)}:\\
    The compiler moves 3 independent instructions that have to be executed in any case immediately after the branch instruction into the so-called branch delay slots. When such instructions are complete the branch outcome is known and no stalls are required.
\end{enumerate}

To reduce the control hazard time penalty, we can shift both the decision about taken or not taken and the BTA calculation in the ID stage. This requires an additional adder, but it decreases the possible stalls from 3 to 1.
This is not a general rule. In deeply pipelined processors, the control hazard penalties could be very large in terms of wasted clock cycles and can not be solved so easily.

\subsection{Performance of pipelines with stalls}
$Speedup = \frac{CPI_{unpipelined}}{CPI_{pipelined}} * \frac{Tclk_{unpipelined}}{Tclk_{pipelined}}$
\\
$CPI_{pipelined} = Ideal CPI + N_{stalls} = 1 + N_{stalls}$

If we ignore the pipeline overhead time we have that: $Tclk_unpelined = Tclk_pipelined$\\
If all instructions take the same number of cycles: $CPI_{unpipelined} = pipeline-depth$

\section{Exception}
The term exceptions cover all the possible exceptional situations whereby the normal execution order of instructions is changed.

Many differences exist between various CPUs.

\paragraph{Some sources of exception}
\begin{enumerate}
    \item Conditions arising from instruction execution (e.g., overflow, FP anomaly)
    \item External interrupts (e.g., I/O device request)
    \item System calls (traps)
    \item Memory-related exceptions (e.g., cache misses, page fault, memory protection violation, misaligned memory access)
    \item Undefined Opcode6.Hardware malfunctions and power failures
\end{enumerate}

\paragraph{Some features}
\begin{itemize}
    \item Synchronous vs. Asynchronous
    \item User requested vs. coerced
    \item User maskable vs. unmaskable
    \item Within vs. between instructions
    \item Resume vs. terminate
\end{itemize}

\paragraph{Exception handling}
\begin{enumerate}
    \item Exception is associated with the only instruction presently being executed
    \item Exceptions are managed by appropriate routines (e.g., Exception Service Routine or ESR)
    \item When an exception is detected, the CU looks into a vector table. Each row of this table contains the memory address of the corresponding ESR
    \item The ESR saves the PC of the excepting instruction, runs the instruction to handle the corresponding exception and finally returns to the original program if the exception requires resuming 
\end{enumerate}

In pipelined CPUs, the situation is much more involved because concurrent instructions are active in the pipeline. Two main problems:
\begin{enumerate}
    \item Recognizing the exception (i.e., associating it with the correct instruction)
    \item Saving the correct machine state
\end{enumerate}

\paragraph{Some exception examples in a pipeline}

\begin{itemize}
    \item \textit{Exceptions arising from instruction execution (e.g. overflow)}: usually raised during stage EX(i.e., within an instruction). They are also coerced, generally user-maskable and they require a resume. 
    \item \textit{External (I/O) interrupts}: Asynchronous, coerced exceptions requiring a resume. The ISR are usually served when the interrupted instruction is in the WB stage(i.e., between subsequent instructions).
    \item \textit{Cache miss}: actually, only data cache miss are considered exceptions (instruction cache misses are directly managed by hardware, which stalls the CPU before IF phase). These exceptions (like page faults) are detected in MEM stage, are coerced, synchronous and non-maskable.
    \item \textit{Non-existing OP code}: may be due to a compiler error, to a memory fault but also, in CPUs belonging to “families”, to instructions invoking functional units not present in the particular device used. This exception is raised in the ID stage;it is synchronous, coerced, non-maskable and leads to program termination.
\end{itemize}

\section{Advanced pipelining}
\subsection{Superpipelining}
A superpipelined processor has a pipeline where each logical step (IF, ID, EX, MEM, WB) is subdivided into simpler multiple pipeline stages. So smaller $T_{CLK}$.

Reduction of stage complexity is limited by four factors:
\begin{enumerate}
    \item \textit{Imbalance problems}:\\
    Imbalance between stages reduces performance because the clock period can not be shorter than the time needed for the slowest pipeline stage
    \item \textit{Pipeline overhead time}:\\
    It results from the combination of two contributions:
    \begin{itemize}
        \item Pipeline register delay: this is due to setup and propagation time through the register. This is constant and related to technology 
        \item Clock skew: worst-case delay between active clock signal edges in two points of a digital system (e.g., between any two pipeline registers)
    \end{itemize}
    The sum of these two contributions represents lower bound to clock cycle.
    \item \textit{Growing data dependences}:\\
    This leads to a higher number of bubbles in a deeper pipeline–performance loss due to data hazards increases
    \item \textit{Longer control hazards}:\\
    imply slower branches in case of wrong predictions
\end{enumerate}

Summing up: cycle time is shorter but the number of cycles required by a given program becomes larger.

Certain operations, such as floating point, may require multiple cycles to complete so it's impractical to have them complete in one cycle.
The EX stage will be repeated as many times as necessary.

\includegraphics[width=\textwidth]{images/superpipeline.png}

\paragraph{Problems}
\begin{itemize}
    \item Instructions may complete in a different order than they were issued
    \item WAW hazards are now possible, since instructions no longer reach WB in order
    \item WAR are still not possible, since registers are still read in ID, and instructions go through ID in order
    \item Stalls due to RAW will be more frequent, since instructions have longer latency. Instructions stalls for long periods awaiting the results from the floating point operations.
    \item Structural hazard: Instructions reach MEM and WB simultaneously!
\end{itemize}

\subsection{Superscalar}
Superscalar architecture is a single processor that can execute several scalar operations in parallel.
\begin{itemize}
    \item Using different dedicated pipelines, implemented on the basis of the classes of instructions that are more frequently used on a given architecture.
    \item Using multiple identical pipelines, i.e. multiple copies of a given physical pipeline.
\end{itemize}
